{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for using variational autoencoder for IPW sampling for IST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/farhadyar/Documents/Project_PTVAE/progs/github_repo/LatentSubgroups\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cd(\"../.\") \n",
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/Documents/Project_PTVAE/progs/github_repo/LatentSubgroups/Project.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "if isfile(\"Project.toml\") && isfile(\"Manifest.toml\")\n",
    "    Pkg.activate(\".\")\n",
    "end\n",
    "\n",
    "# Pkg.instantiate()\n",
    "using IJulia\n",
    "\n",
    "using Revise\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using DecisionTree.predict in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "includet(\"../AIQN/AIQN.jl\")\n",
    "includet(\"../src/structs.jl\")\n",
    "includet(\"../src/report.jl\")\n",
    "includet(\"../src/transformations.jl\")\n",
    "includet(\"../src/VAE.jl\")\n",
    "includet(\"../src/load_data.jl\")\n",
    "includet(\"../src/evaluation/evaluation.jl\")\n",
    "includet(\"../src/classification.jl\")\n",
    "includet(\"../src/GLM.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, dataTypeArray,args = load_dataset()\n",
    "\n",
    "args.η = 0.001f0\n",
    "args.λ = 0.01f0\n",
    "args.β =   0.5\n",
    "args.batch_size = 128\n",
    "args.epochs = 1000\n",
    "args.seed = 42\n",
    "args.input_dim = 15\n",
    "args.latent_dim = 2\n",
    "args.hidden_dim = 22\n",
    "args.verbose_freq = 100\n",
    "args.tblogger_flag = true\n",
    "args.hyperopt_flag = false\n",
    "args.pre_transformation = true\n",
    "args.bimodality_score_threshold = 0.0f0\n",
    "args.scaling = true\n",
    "args.scaling_method = \"scaling\"\n",
    "args.AIQN = false\n",
    "args.multimodal_encoder = true\n",
    "args.latent_fusion_method = false\n",
    "args.IPW_sampling = true\n",
    "args.subpopulation_mode = 2\n",
    "args.grid_point_size = 0.2f0\n",
    "args.δ = 0.1f0\n",
    "args.pre_transformation = true\n",
    "args.AIQN = false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (transformations and scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation of Box-Cox transformation parameters:\n",
      "\n",
      " λ1 estimation for feature 1:\n",
      "\n",
      " λ1 estimation for feature 2:\n",
      "\n",
      " λ1 estimation for feature 3:\n",
      "Epoch 100: loss = 6638.778709543711\n",
      "Epoch 200: loss = 6612.757357658436\n",
      "Epoch 300: loss = 6596.106400311471\n",
      "Epoch 400: loss = 6586.368628559732\n",
      "Epoch 500: loss = 6581.233484258955\n",
      "Epoch 600: loss = 6578.818753228476\n",
      "Epoch 700: loss = 6577.814211140042\n",
      "Epoch 800: loss = 6577.446172413086\n",
      "Epoch 900: loss = 6577.327675036206\n",
      "Epoch 1000: loss = 6577.294189503509\n",
      "λ1 estimation for feature 3 is converged at epoch 1033!\n",
      "\n",
      "\n",
      " λ1 estimation for feature 4:\n",
      "\n",
      " λ1 estimation for feature 5:\n",
      "Epoch 100: loss = 6638.778709543711\n",
      "Epoch 200: loss = 6612.757357658436\n",
      "Epoch 300: loss = 6596.106400311471\n",
      "Epoch 400: loss = 6586.368628559732\n",
      "Epoch 500: loss = 6581.233484258955\n",
      "Epoch 600: loss = 6578.818753228476\n",
      "Epoch 700: loss = 6577.814211140042\n",
      "Epoch 800: loss = 6577.446172413086\n",
      "Epoch 900: loss = 6577.327675036206\n",
      "Epoch 1000: loss = 6577.294189503509\n",
      "Epoch 1100: loss = 6469.07917047368\n",
      "Epoch 1200: loss = 6446.572853312277\n",
      "Epoch 1300: loss = 6434.372733863979\n",
      "Epoch 1400: loss = 6426.490432414645\n",
      "Epoch 1500: loss = 6421.058264419082\n",
      "Epoch 1600: loss = 6417.203443530036\n",
      "Epoch 1700: loss = 6414.433132566832\n",
      "Epoch 1800: loss = 6412.436166034413\n",
      "Epoch 1900: loss = 6411.001272646419\n",
      "λ1 estimation for feature 5 is converged at epoch 1952!\n",
      "\n",
      "\n",
      " λ1 estimation for feature 6:\n",
      "\n",
      " λ1 estimation for feature 7:\n",
      "\n",
      " λ1 estimation for feature 8:\n",
      "\n",
      " λ1 estimation for feature 9:\n",
      "\n",
      " λ1 estimation for feature 10:\n",
      "\n",
      " λ1 estimation for feature 11:\n",
      "\n",
      " λ1 estimation for feature 12:\n",
      "Epoch 100: loss = 6638.778709543711\n",
      "Epoch 200: loss = 6612.757357658436\n",
      "Epoch 300: loss = 6596.106400311471\n",
      "Epoch 400: loss = 6586.368628559732\n",
      "λ1 estimation for feature 12 is converged at epoch 492!\n",
      "\n",
      "\n",
      " λ1 estimation for feature 13:\n",
      "\n",
      " λ1 estimation for feature 14:\n",
      "\n",
      " λ1 estimation for feature 15:\n",
      "bimodality_score = 0.15474029542341067\n",
      "feature_number = 3\n",
      "peaks_x = [9.225974763946816, 10.193168698424135]\n",
      "valley_x = 9.854650821357072\n",
      "bandwidth_list[i] = 0.41\n",
      "i = 5\n",
      "indexes = [1, 2, 3, 4, 5]\n",
      "bimodality_score = 0.319648221171826\n",
      "feature_number = 5\n",
      "peaks_x = [9511.879863705599, 11290.758738608214]\n",
      "valley_x = 10082.878021081748\n",
      "bandwidth_list[i] = 286.11\n",
      "i = 2862\n",
      "indexes = [1, 59, 117, 175, 233, 291, 349, 407, 465, 523, 581, 639, 697, 755, 813, 871, 929, 987, 1045, 1103, 1161, 1219, 1277, 1335, 1393, 1451, 1509, 1567, 1625, 1683, 1741, 1799, 1857, 1915, 1973, 2031, 2089, 2147, 2205, 2263, 2321, 2379, 2437, 2495, 2553, 2611, 2669, 2727, 2785, 2843, 2862]\n",
      "indexes = [1, 2, 3]\n",
      "anim_list = Any[Animation(\"/var/folders/d5/md8j7hzd7hd4x541d_l6bmzm0000gp/T/jl_XYBo5B\", [\"000001.png\", \"000002.png\", \"000003.png\", \"000004.png\", \"000005.png\"]), Animation(\"/var/folders/d5/md8j7hzd7hd4x541d_l6bmzm0000gp/T/jl_DdPJpW\", [\"000001.png\", \"000002.png\", \"000003.png\", \"000004.png\", \"000005.png\", \"000006.png\", \"000007.png\", \"000008.png\", \"000009.png\", \"000010.png\", \"000011.png\", \"000012.png\", \"000013.png\", \"000014.png\", \"000015.png\", \"000016.png\", \"000017.png\", \"000018.png\", \"000019.png\", \"000020.png\", \"000021.png\", \"000022.png\", \"000023.png\", \"000024.png\", \"000025.png\", \"000026.png\", \"000027.png\", \"000028.png\", \"000029.png\", \"000030.png\", \"000031.png\", \"000032.png\", \"000033.png\", \"000034.png\", \"000035.png\", \"000036.png\", \"000037.png\", \"000038.png\", \"000039.png\", \"000040.png\", \"000041.png\", \"000042.png\", \"000043.png\", \"000044.png\", \"000045.png\", \"000046.png\", \"000047.png\", \"000048.png\", \"000049.png\", \"000050.png\", \"000051.png\"]), Animation(\"/var/folders/d5/md8j7hzd7hd4x541d_l6bmzm0000gp/T/jl_5WEUfm\", [\"000001.png\", \"000002.png\", \"000003.png\"])]\n",
      "\n",
      " Power parameters estimation for feature 1:\n",
      "The feature is not bimodal! \n",
      "\n",
      "\n",
      " Power parameters estimation for feature 2:\n",
      "The feature is not bimodal! \n",
      "\n",
      "\n",
      " Power parameters estimation for feature 3:\n",
      "Epoch 1000: loss = 1.6022818612897458\n",
      "Epoch 2000: loss = 0.7069873900037551\n",
      "Epoch 3000: loss = 0.41039801472878357\n",
      "Epoch 4000: loss = 0.2855152325363759\n",
      "Epoch 5000: loss = 0.18913363269176076\n",
      "Power parameters estimation for 3 is converged at epoch 5818!\n",
      "\n",
      " Power parameters estimation for feature 4:\n",
      "The feature is not bimodal! \n",
      "\n",
      "\n",
      " Power parameters estimation for feature 5:\n",
      "Epoch 1000: loss = 56131.905569997136\n",
      "Epoch 2000: loss = 24771.900276745568\n",
      "Epoch 3000: loss = 13593.178998383872\n",
      "Epoch 4000: loss = 8105.074795701137\n",
      "Epoch 5000: loss = 5033.276745183808\n",
      "Epoch 6000: loss = 3196.269449223968\n",
      "Epoch 7000: loss = 2056.675990257365\n",
      "Epoch 8000: loss = 1334.3377286377518\n",
      "Epoch 9000: loss = 870.4669956257167\n",
      "Epoch 10000: loss = 570.2368191910309\n",
      "Epoch 11000: loss = 375.1081512711071\n",
      "Epoch 12000: loss = 248.21607792690202\n",
      "Epoch 13000: loss = 167.3443457842336\n",
      "Epoch 14000: loss = 157.55136294602175\n",
      "Epoch 15000: loss = 144.56661006620539\n",
      "Epoch 16000: loss = 128.7388778268978\n",
      "Epoch 17000: loss = 111.1698676397798\n",
      "Epoch 18000: loss = 93.39021686358262\n",
      "Epoch 19000: loss = 76.80885639208066\n",
      "Epoch 20000: loss = 62.32038421563925\n",
      "Epoch 21000: loss = 50.23648605247041\n",
      "Epoch 22000: loss = 40.43856357608132\n",
      "Epoch 23000: loss = 32.59802842168557\n",
      "Epoch 24000: loss = 26.352049361285367\n",
      "Epoch 25000: loss = 21.385031626075147\n",
      "Epoch 26000: loss = 17.439699611532973\n",
      "Epoch 27000: loss = 14.306701102187063\n",
      "Epoch 28000: loss = 11.815596333134295\n",
      "Epoch 29000: loss = 9.829053265544204\n",
      "Epoch 30000: loss = 8.237995006338352\n",
      "Epoch 31000: loss = 6.956594026232395\n",
      "Epoch 32000: loss = 5.866803491448955\n",
      "Power parameters estimation for 5 is converged at epoch 32130!\n",
      "\n",
      " Power parameters estimation for feature 6:\n",
      "The feature is not bimodal! \n",
      "\n",
      "\n",
      " Power parameters estimation for feature 7:\n",
      "The feature is not bimodal! \n",
      "\n",
      "\n",
      " Power parameters estimation for feature 8:\n",
      "The feature is not bimodal! \n",
      "\n",
      "\n",
      " Power parameters estimation for feature 9:\n",
      "The feature is not bimodal! \n",
      "\n",
      "\n",
      " Power parameters estimation for feature 10:\n",
      "The feature is not bimodal! \n",
      "\n",
      "\n",
      " Power parameters estimation for feature 11:\n",
      "The feature is not bimodal! \n",
      "\n",
      "\n",
      " Power parameters estimation for feature 12:\n",
      "The feature is not bimodal! \n",
      "\n",
      "\n",
      " Power parameters estimation for feature 13:\n",
      "The feature is not bimodal! \n",
      "\n",
      "\n",
      " Power parameters estimation for feature 14:\n",
      "The feature is not bimodal! \n",
      "\n",
      "\n",
      " Power parameters estimation for feature 15:\n",
      "The feature is not bimodal! \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Saved animation to /Users/farhadyar/Documents/Project_PTVAE/progs/github_repo/LatentSubgroups/runs/run_465/pre_transformation/power_transformation/animations/anim_1.gif\n",
      "└ @ Plots /Users/farhadyar/.julia/packages/Plots/aRJ6C/src/animation.jl:149\n",
      "┌ Info: Saved animation to /Users/farhadyar/Documents/Project_PTVAE/progs/github_repo/LatentSubgroups/runs/run_465/pre_transformation/power_transformation/animations/anim_2.gif\n",
      "└ @ Plots /Users/farhadyar/.julia/packages/Plots/aRJ6C/src/animation.jl:149\n",
      "┌ Info: Saved animation to /Users/farhadyar/Documents/Project_PTVAE/progs/github_repo/LatentSubgroups/runs/run_465/pre_transformation/power_transformation/animations/anim_3.gif\n",
      "└ @ Plots /Users/farhadyar/.julia/packages/Plots/aRJ6C/src/animation.jl:149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; … ; 1.0 0.0 … 0.0 0.0; 0.0 0.0 … 1.0 0.0], preprocess_params\n",
       "  input_dim: Int64 15\n",
       "  pre_transformation_type: String \"power\"\n",
       "  qt_array: Array{QuantileTransformer}((0,))\n",
       "  n_quantiles: Int64 100\n",
       "  λ2: Array{Float32}((15,)) Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
       "  λ1: Array{Float32}((15,)) Float32[1.0, 1.0, 0.561754, 1.0, 2.3622098, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2799291, 1.0, 1.0, 1.0]\n",
       "  box_cox_epochs: Int64 5000\n",
       "  box_cox_η: Float32 0.001f0\n",
       "  μ: Array{Float32}((15,)) Float32[0.0, 0.0, -2.6758428, 0.0, -176.34117, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.05596, 0.0, 0.0, 0.0]\n",
       "  σ: Array{Float32}((15,)) Float32[0.5, 0.5, 2.5508883, 0.5, 167.66948, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 2.470179, 0.5, 0.5, 0.5]\n",
       "  shift: Array{Float32}((15,)) Float32[0.0, 0.0, 7.6397266, 0.0, 11289.734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "  peak1: Array{Float32}((15,)) Float32[0.0, 0.0, 9.225975, 0.0, 9511.88, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "  peak2: Array{Float32}((15,)) Float32[0.0, 0.0, 10.193169, 0.0, 11290.759, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "  peak_rng: Array{Float32}((15,)) Float32[1.0, 1.0, 1.9738932, 1.0, 8.707808, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
       "  min: Array{Float32}((15,)) Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "  max: Array{Float32}((15,)) Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "  power: Array{Float32}((15,)) Float32[1.0, 1.0, 0.8780628, 1.0, 0.21714988, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
       "  power_epochs: Int64 50000\n",
       "  power_η: Float32 0.001f0\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Random.seed!(11)\n",
    "\n",
    "\n",
    "# preprocess_ps = load_struct(\"./runs/run_299/pre_transformation/preprocess_params.bson\")\n",
    "# preprocessed_data = Matrix(CSV.read(\"./runs/run_299/pre_transformation/scaling/scaled_data.csv\", DataFrame, header = false))'\n",
    "# preprocess_ps = load_struct(\"./runs/run_330/pre_transformation/preprocess_params.bson\")\n",
    "\n",
    "preprocess_ps = preprocess_params(input_dim = args.input_dim)\n",
    "preprocessed_data, preprocess_ps = preprocess!(args, preprocess_ps, x, dataTypeArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: loss = 4.526013705933173\n",
      "Epoch 200: loss = 4.416771090024903\n",
      "Epoch 300: loss = 3.7137217665476117\n",
      "Epoch 400: loss = 3.050962359359918\n",
      "Epoch 500: loss = 2.938897421004409\n",
      "Epoch 600: loss = 2.7679218114066755\n",
      "Epoch 700: loss = 2.7483864418612134\n",
      "Epoch 800: loss = 2.745697237370605\n",
      "Epoch 900: loss = 2.5912321706051284\n",
      "Epoch 1000: loss = 2.8413711428029957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(multimodal_vae(Dense(12 => 12, tanh), Dense(3 => 3, tanh), Dense(12 => 2), Dense(3 => 2), Dense(12 => 2), Dense(3 => 2), Dense(2 => 22, tanh), Dense(22 => 3), Dense(22 => 3), Dense(22 => 12, σ), Bool[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 3, 12, false, 0.5, TBLogger(\"/Users/farhadyar/Documents/Project_PTVAE/progs/github_repo/LatentSubgroups/runs/run_465/vae\"), min_level=Info, purge_step=1000)), DataLoader{Adjoint{Float64, Matrix{Float64}}, Random._GLOBAL_RNG, Val{nothing}}([1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; … ; 1.0 0.0 … 0.0 0.0; 0.0 0.0 … 1.0 0.0], 128, false, true, true, false, Val{nothing}(), Random._GLOBAL_RNG()), Any[11.680187640288729, 11.010218448483949, 9.954829126139405, 8.567187829222917, 7.389415028689303, 6.808702447066272, 6.612440767058817, 6.451322904498741, 6.349112835907086, 6.271153444085775  …  2.5447181585065963, 2.820550253736385, 2.5637603905309794, 2.544497734729346, 2.5474999878893416, 2.7657096345537013, 2.5712448021982626, 2.6254321437694292, 2.757851824232486, 2.8413711428029957])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if args.hyperopt_flag\n",
    "    trainVAE_hyperparams_opt!(preprocessed_data, x, dataTypeArray, preprocess_ps, args)\n",
    "else\n",
    "    model, training_data, loss_array_vae = trainVAE!(preprocessed_data, x, dataTypeArray, preprocess_ps, args)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPL Ghostscript 10.01.2 (2023-06-21)\n",
      "Copyright (C) 2023 Artifex Software, Inc.  All rights reserved.\n",
      "This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY:\n",
      "see the file COPYING for details.\n",
      "Processing pages 1 through 1.\n",
      "Page 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Process(`\u001b[4mcp\u001b[24m \u001b[4m./runs/run_465/vae/prior_sampling/IPW_sampling/propensity_ist_fig.pdf\u001b[24m \u001b[4m./figures/Figure5_propensity_ist.pdf\u001b[24m`, ProcessExited(0))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the input and output filenames\n",
    "input_pdf = \"./$(args.current_run_path)/vae/prior_sampling/IPW_sampling/propensity_ist_fig.pdf\"\n",
    "output_eps = \"./figures/Figure5_propensity_ist.eps\"\n",
    "output_pdf = \"./figures/Figure5_propensity_ist.pdf\"\n",
    "\n",
    "# Construct the Ghostscript command\n",
    "command = `gs -dNOPAUSE -dBATCH -dEPSCrop -r300 -sDEVICE=eps2write -sOutputFile=$output_eps $input_pdf`\n",
    "\n",
    "# Run the command\n",
    "run(command)\n",
    "\n",
    "\n",
    "# Construct the Ghostscript command\n",
    "command = `cp  $input_pdf $output_pdf`\n",
    "\n",
    "# Run the command\n",
    "run(command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.7",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbe963f0ca08ef66471a02bca175dbdba8b50cc2ceaf0dd1c5a92a4fd1518261"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
