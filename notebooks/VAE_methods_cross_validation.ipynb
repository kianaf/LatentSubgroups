{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for using variational autoencoder and the choice of variables in struct depends on which version you want to train. \n",
    "\n",
    "- with Pre-transformations\n",
    "- with AIQN\n",
    "- standard VAE\n",
    "\n",
    "The results in the paper have the following architecture for the sim data:\n",
    "\n",
    "    data_string::String = \"sim\" \n",
    "    η::Float32 = 1e-3                                                                                                \n",
    "    λ::Float32 = 0.01f0\n",
    "    β::Float64 = 0.5                                                                                      \n",
    "    batch_size::Int = 128                                                                                            \n",
    "    epochs::Int = 500                                                                                                 \n",
    "    seed::Int = 42                                                                                                  \n",
    "    input_dim::Int = 21                                                                                               \n",
    "    latent_dim::Int = 2                                                                                               \n",
    "    hidden_dim::Int = 28                                                                                              \n",
    "    verbose_freq::Int = 100                                                                                          \n",
    "    hyperopt_flag::Bool = false       \n",
    "    multimodal_encoder::Bool = true   \n",
    "\n",
    "    pre_transformation::Bool =  true                                                                                 \n",
    "    bimodality_score_threshold::Float32 = 0                                                                         \n",
    "    \n",
    "    scaling::Bool = true                                                                                             \n",
    "    scaling_method::String = \"scaling\" \n",
    "                                                                                    \n",
    "    AIQN::Bool = false                                                                                               \n",
    "                                                                                 \n",
    "    latent_fusion_method::Bool = false                                                                                     \n",
    "\n",
    "\n",
    "Now for QVAE:\n",
    "    AIQN = true\n",
    "\n",
    "for standard VAE:\n",
    "    pre_transformation = false\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The results in the paper have the following architecture for the IST data:\n",
    "\n",
    "    data_string::String = \"ist_randomization_data_smaller_no_west_no_south_aug5\" \n",
    "    η::Float32 = 5e-4                                                                                                \n",
    "    λ::Float32 = 0.01f0\n",
    "    β::Float64 = 0.5                                                                                      \n",
    "    batch_size::Int = 32                                                                                            \n",
    "    epochs::Int = 1000                                                                                                 \n",
    "    seed::Int = 42                                                                                                  \n",
    "    input_dim::Int = 21                                                                                               \n",
    "    latent_dim::Int = 2                                                                                               \n",
    "    hidden_dim::Int = 28                                                                                              \n",
    "    verbose_freq::Int = 100                                                                                          \n",
    "    hyperopt_flag::Bool = false       \n",
    "    multimodal_encoder::Bool = true   \n",
    "\n",
    "    pre_transformation::Bool =  true                                                                                 \n",
    "    bimodality_score_threshold::Float32 = 0                                                                         \n",
    "    \n",
    "    scaling::Bool = true                                                                                             \n",
    "    scaling_method::String = \"scaling\" \n",
    "                                                                                    \n",
    "    AIQN::Bool = false                                                                                               \n",
    "                                                                                 \n",
    "    latent_fusion_method::Bool = false                                                                                     \n",
    "\n",
    "\n",
    "Now for QVAE:\n",
    "    AIQN = true\n",
    "\n",
    "for standard VAE:\n",
    "    pre_transformation = false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/farhadyar/Documents/Project_PTVAE/progs/github_repo/LatentSubgroups\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cd(\"../.\") \n",
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/Documents/Project_PTVAE/progs/github_repo/LatentSubgroups/Project.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "if isfile(\"Project.toml\") && isfile(\"Manifest.toml\")\n",
    "    Pkg.activate(\".\")\n",
    "end\n",
    "\n",
    "# Pkg.instantiate()\n",
    "using IJulia\n",
    "\n",
    "using Revise\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using DecisionTree.predict in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "includet(\"../AIQN/AIQN.jl\")\n",
    "includet(\"../src/structs.jl\")\n",
    "includet(\"../src/report.jl\")\n",
    "includet(\"../src/transformations.jl\")\n",
    "includet(\"../src/VAE.jl\")\n",
    "includet(\"../src/load_data.jl\")\n",
    "includet(\"../src/evaluation/evaluation.jl\")\n",
    "includet(\"../src/classification.jl\")\n",
    "includet(\"../src/GLM.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, dataTypeArray,args = load_dataset()\n",
    "\n",
    "args.cross_validation_flag = true\n",
    "args.n_folds = 10\n",
    "\n",
    "\n",
    "if args.data_string == \"sim\"\n",
    "    \n",
    "    args.β = 0.5\n",
    "    args.η = 1e-3\n",
    "    args.epochs = 500\n",
    "    args.multimodal_encoder = true\n",
    "    args.batch_size = 32\n",
    "    args.latent_dim = 2\n",
    "    args.hidden_dim = 28\n",
    "    args.scaling_method = \"scaling\"\n",
    "    args.IPW_sampling = false\n",
    "\n",
    "else contains(args.data_string, \"ist\")\n",
    "    args.β = 0.5\n",
    "    args.η = 1e-3\n",
    "    args.epochs = 1000\n",
    "    args.multimodal_encoder = true\n",
    "    args.batch_size = 128\n",
    "    args.latent_dim = 2\n",
    "    args.hidden_dim = 22\n",
    "    args.scaling_method = \"scaling\"\n",
    "end\n",
    "\n",
    "\n",
    "args.pre_transformation = true\n",
    "\n",
    "args.AIQN = false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (transformations and scaling) &\n",
    "## Training Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: loss = 5.502113882279908\n",
      "Epoch 200: loss = 5.4116579955094455\n",
      "Epoch 300: loss = 4.400034235715316\n",
      "Epoch 400: loss = 4.011372685943244\n",
      "Epoch 500: loss = 3.789506821617326\n",
      "Epoch 600: loss = 3.7079652158293634\n",
      "Epoch 700: loss = 3.7726091165067652\n",
      "Epoch 800: loss = 3.7597719573126605\n",
      "Epoch 900: loss = 3.6094665635452277\n",
      "Epoch 1000: loss = 3.5921770910092614\n",
      "Epoch 100: loss = 5.489959052885837\n",
      "Epoch 200: loss = 5.402479480383107\n",
      "Epoch 300: loss = 4.503188645114546\n",
      "Epoch 400: loss = 3.9047815912539874\n",
      "Epoch 500: loss = 3.7720565548993936\n",
      "Epoch 600: loss = 3.6873183694795473\n",
      "Epoch 700: loss = 3.7221561545879123\n",
      "Epoch 800: loss = 3.7553641618688274\n",
      "Epoch 900: loss = 3.6570135646580266\n",
      "Epoch 1000: loss = 3.536912299690136\n",
      "Epoch 100: loss = 5.4578082559754675\n",
      "Epoch 200: loss = 5.363489345120011\n",
      "Epoch 300: loss = 4.38275257857288\n",
      "Epoch 400: loss = 3.829970627556807\n",
      "Epoch 500: loss = 3.7571105187950735\n",
      "Epoch 600: loss = 3.612655014523681\n",
      "Epoch 700: loss = 3.730112614218507\n",
      "Epoch 800: loss = 3.651998414668601\n",
      "Epoch 900: loss = 3.5479580619947986\n",
      "Epoch 1000: loss = 3.5510649824152916\n",
      "Epoch 100: loss = 5.4969130641810455\n",
      "Epoch 200: loss = 5.400164421222832\n",
      "Epoch 300: loss = 4.311662776989444\n",
      "Epoch 400: loss = 3.8801956254569374\n",
      "Epoch 500: loss = 3.757812694259496\n",
      "Epoch 600: loss = 3.6591548969682957\n",
      "Epoch 700: loss = 3.643999162594088\n",
      "Epoch 800: loss = 3.6572816211579666\n",
      "Epoch 900: loss = 3.5689510933404733\n",
      "Epoch 1000: loss = 3.851944821622449\n",
      "Epoch 100: loss = 5.505941827608182\n",
      "Epoch 200: loss = 5.4058065647038465\n",
      "Epoch 300: loss = 4.15931079877074\n",
      "Epoch 400: loss = 3.9768278735883866\n",
      "Epoch 500: loss = 3.7536865143551457\n",
      "Epoch 600: loss = 3.6402102017105062\n",
      "Epoch 700: loss = 3.6410307437601226\n",
      "Epoch 800: loss = 3.7376383948344256\n",
      "Epoch 900: loss = 3.6200376375990455\n",
      "Epoch 1000: loss = 3.517504558008983\n",
      "Epoch 100: loss = 5.496736691977\n",
      "Epoch 200: loss = 5.4049006409465905\n",
      "Epoch 300: loss = 4.430761233293995\n",
      "Epoch 400: loss = 3.96930443329266\n",
      "Epoch 500: loss = 3.800284489183082\n",
      "Epoch 600: loss = 3.7028386123220822\n",
      "Epoch 700: loss = 3.7172262326629224\n",
      "Epoch 800: loss = 3.7156308388138473\n",
      "Epoch 900: loss = 3.6370490635305184\n",
      "Epoch 1000: loss = 3.7609281031761603\n",
      "Epoch 100: loss = 5.502189299222641\n",
      "Epoch 200: loss = 5.410676298924406\n",
      "Epoch 300: loss = 4.378718371410071\n",
      "Epoch 400: loss = 3.909227018566637\n",
      "Epoch 500: loss = 3.7608430202042453\n",
      "Epoch 600: loss = 3.7941211289448336\n",
      "Epoch 700: loss = 3.710801505405256\n",
      "Epoch 800: loss = 3.679692686069206\n",
      "Epoch 900: loss = 3.610690274719295\n",
      "Epoch 1000: loss = 3.5637640201645664\n",
      "Epoch 100: loss = 5.507656596262411\n",
      "Epoch 200: loss = 5.418641255432594\n",
      "Epoch 300: loss = 4.381433462015709\n",
      "Epoch 400: loss = 3.9377017622285733\n",
      "Epoch 500: loss = 3.793581495710293\n",
      "Epoch 600: loss = 3.7353368883995928\n",
      "Epoch 700: loss = 3.6446129224007575\n",
      "Epoch 800: loss = 3.619071619080933\n",
      "Epoch 900: loss = 3.5890598379874\n",
      "Epoch 1000: loss = 3.5323246616102035\n",
      "Epoch 100: loss = 5.486421948590363\n",
      "Epoch 200: loss = 5.385672845866569\n",
      "Epoch 300: loss = 4.477758467504871\n",
      "Epoch 400: loss = 3.8805002443933465\n",
      "Epoch 500: loss = 3.7394802580320907\n",
      "Epoch 600: loss = 3.655311905257989\n",
      "Epoch 700: loss = 3.5735012409885063\n",
      "Epoch 800: loss = 3.6069906209996176\n",
      "Epoch 900: loss = 3.5532278991671045\n",
      "Epoch 1000: loss = 3.5322518449771354\n",
      "Epoch 100: loss = 5.507986076160232\n",
      "Epoch 200: loss = 5.3952470222922795\n",
      "Epoch 300: loss = 4.304747443211426\n",
      "Epoch 400: loss = 3.8548543331076237\n",
      "Epoch 500: loss = 3.7171551324874024\n",
      "Epoch 600: loss = 3.7162957554736242\n",
      "Epoch 700: loss = 3.6138483875583014\n",
      "Epoch 800: loss = 3.5816579560184687\n",
      "Epoch 900: loss = 3.633523337429189\n",
      "Epoch 1000: loss = 3.526764369049317\n"
     ]
    }
   ],
   "source": [
    "Random.seed!(11)\n",
    "\n",
    "if args.cross_validation_flag\n",
    "\n",
    "    reconstruction_train_val_sets = []\n",
    "\n",
    "    cross_val_run_path = string(args.current_run_path, \"/$(args.n_folds)fold_cross_validation\")\n",
    "    mkdir(cross_val_run_path)\n",
    "\n",
    "    cross_val_sets = create_cross_validation_sets(x, args.n_folds)\n",
    "\n",
    "    for fold = 1:args.n_folds    \n",
    "\n",
    "        train_set, val_set = cross_val_sets[fold]\n",
    "               \n",
    "        args.current_run_path = string(cross_val_run_path, \"/fold_$(fold)\")\n",
    "\n",
    "\n",
    "        mkdir(args.current_run_path)\n",
    "\n",
    "        # write the train_set and val_set as csv in args.current_run_path\n",
    "        writedlm(string(args.current_run_path, \"/\", \"train.csv\"),  train_set, ',')\n",
    "        writedlm(string(args.current_run_path, \"/\", \"val.csv\"),  val_set, ',')\n",
    "          \n",
    "        # preprocess_ps = preprocess_params(input_dim = args.input_dim)\n",
    "        preprocess_ps = preprocess_params(input_dim = args.input_dim, pre_transformation_type = \"quantile\")\n",
    "\n",
    "        \n",
    "        preprocessed_data, preprocess_ps = preprocess!(args, preprocess_ps, train_set, dataTypeArray)\n",
    "        preprocessed_data_val, preprocess_ps = preprocess_test_data(args, preprocess_ps, val_set, dataTypeArray)\n",
    "\n",
    "        if args.hyperopt_flag \n",
    "            println(\"cross_validation and hyper parameter optimization is not implemented!\")\n",
    "            println(\"hyperopt_flag is changed to false\")\n",
    "        else\n",
    "            val_data = get_data(preprocessed_data_val, args.batch_size)\n",
    "\n",
    "            model, training_data, reconstruction_train_val_set = trainVAE!(preprocessed_data, train_set, dataTypeArray, preprocess_ps, args; val_data = val_data)\n",
    "\n",
    "            push!(reconstruction_train_val_sets, reconstruction_train_val_set)\n",
    "\n",
    "            \n",
    "            save_vae_results(val_data, preprocessed_data, val_set, model, preprocess_ps, args, [], true)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    mkdir(string(cross_val_run_path, \"/reconstruction_values\"))\n",
    "\n",
    "    @save string(cross_val_run_path, \"/reconstruction_values/reconstruction_values\") reconstruction_train_val_sets\n",
    "\n",
    "else\n",
    "    preprocess_ps = preprocess_params(input_dim = args.input_dim)\n",
    "    preprocessed_data, preprocess_ps = preprocess!(args, preprocess_ps, x, dataTypeArray)\n",
    "\n",
    "    if args.hyperopt_flag\n",
    "        trainVAE_hyperparams_opt!(preprocessed_data, x, dataTypeArray, preprocess_ps, args)\n",
    "    else\n",
    "        model, training_data, loss_array_vae = trainVAE!(preprocessed_data, x, dataTypeArray, preprocess_ps, args)\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.7",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbe963f0ca08ef66471a02bca175dbdba8b50cc2ceaf0dd1c5a92a4fd1518261"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
